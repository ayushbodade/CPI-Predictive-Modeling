{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./consumer_price_index.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing incosistencies\n",
    "df.replace('November ', 'November', inplace=True)\n",
    "df.replace('Marcrh', 'March', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df = df.query('Sector == \"Rural+Urban\"')\n",
    "u_df = df.query('Sector == \"Urban\"')\n",
    "r_df = df.query('Sector == \"Rural\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing due to Covid-19\n",
    "u_df[u_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing due to Covid-19\n",
    "ru_df[ru_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df[r_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df.drop('Housing', inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df = ru_df.dropna()\n",
    "u_df = u_df.dropna()\n",
    "r_df = r_df.dropna()\n",
    "ru_df['Housing'] = ru_df['Housing'].astype(float)\n",
    "u_df['Housing'] = u_df['Housing'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting General CPI from 2013 - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 April data missing \n",
    "ru_df.query(\"Year == 2019\")\n",
    "\n",
    "# 2021 April and May data missing\n",
    "ru_df.query(\"Year == 2021\")\n",
    "\n",
    "all_months = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "              'August', 'September', 'October', 'November',\n",
    "              'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 16))\n",
    "\n",
    "for i in range(2013, 2024):\n",
    "    general_cpi = ru_df.query(\"Year == @i and Sector == 'Rural+Urban'\")['General index']\n",
    "    if i == 2019:\n",
    "        general_cpi.loc[3] = np.nan\n",
    "    if i == 2020:\n",
    "        general_cpi.loc[3] = np.nan\n",
    "        general_cpi.loc[4] = np.nan\n",
    "    if i == 2023:\n",
    "        for j in range(3, 13):  # Use a different variable name for the inner loop\n",
    "            general_cpi.loc[j] = np.nan\n",
    "    ax = axes[(i-2013) // 3, (i-2013) % 3]  # Select the appropriate subplot\n",
    "    if general_cpi.notna().any():\n",
    "        ax.plot(all_months, np.where(pd.isna(general_cpi), np.nan, general_cpi), marker='o')\n",
    "        ax.set_title(f\"General CPI over {i}\")\n",
    "        ax.set_xlabel('Months')\n",
    "        ax.set_ylabel('General CPI')\n",
    "        ax.set_xticks(range(len(all_months)))  # Set the x-axis tick positions\n",
    "        ax.set_xticklabels(all_months, rotation='vertical', ha='center')  # Set the x-axis tick labels\n",
    "    else: \n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes used to build the model : Rural+Urban & Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat([u_df, ru_df])\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year and Month\n",
    "\n",
    "##### Periodicity: \n",
    "Determine whether the Year-Month combination exhibits periodic patterns. You can create binary features indicating whether a specific month falls within a particular season or whether it belongs to a specific quarter. This can help capture cyclical behavior in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['Year'] = pd.to_datetime(model_df['Year'], format='%Y')\n",
    "model_df['Month'] = pd.to_datetime(model_df['Month'], format='%B')\n",
    "\n",
    "seasons = {\n",
    "    1: 'Winter',\n",
    "    2: 'Winter',\n",
    "    3: 'Spring',\n",
    "    4: 'Spring',\n",
    "    5: 'Spring',\n",
    "    6: 'Summer',\n",
    "    7: 'Summer',\n",
    "    8: 'Summer',\n",
    "    9: 'Autumn',\n",
    "    10: 'Autumn',\n",
    "    11: 'Autumn',\n",
    "    12: 'Winter'\n",
    "}\n",
    "\n",
    "model_df['Season'] = model_df['Month'].map(seasons)\n",
    "\n",
    "quarters = {\n",
    "    1: 'Q1',\n",
    "    2: 'Q1',\n",
    "    3: 'Q1',\n",
    "    4: 'Q2',\n",
    "    5: 'Q2',\n",
    "    6: 'Q2',\n",
    "    7: 'Q3',\n",
    "    8: 'Q3',\n",
    "    9: 'Q3',\n",
    "    10: 'Q4',\n",
    "    11: 'Q4',\n",
    "    12: 'Q4'\n",
    "}\n",
    "\n",
    "model_df['Quarter'] = model_df['Month'].map(quarters)\n",
    "model_df = pd.get_dummies(model_df, columns=['Season', 'Quarter'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sector\n",
    "\n",
    "##### Binary Encoding \n",
    "The binary encoding approach converts the \"Sector\" variable into a single binary column, where \"Urban\" is represented as 1 and \"Rural+Urban\" is represented as 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['Sector_Binary'] = model_df['Sector'].map({'Urban': 1, 'Rural+Urban': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['Housing'] = model_df['Housing'].astype(float)\n",
    "model_df['Sector_Binary'] = model_df['Sector_Binary'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting CPI Distribution for various commodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cpi_cols = {'Sector', 'Sector_Binary', 'Year', 'Month'}\n",
    "cpi_cols = [col for col in model_df.columns if col not in non_cpi_cols]\n",
    "print(len(cpi_cols))\n",
    "for i in cpi_cols:\n",
    "    sns.kdeplot(data=model_df[i])\n",
    "    plt.xlabel('CPI')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'CPI Distribution - {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.drop('Sector',axis=1)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "numeric_cols = model_df.select_dtypes(include='number').columns\n",
    "y = model_df['General index']\n",
    "X = model_df[numeric_cols].drop('General index', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lgb_regressor = lgb.LGBMRegressor()\n",
    "lgb_regressor.fit(X_train_scaled, y_train)\n",
    "y_pred = lgb_regressor.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgb_regressor, '(3)lgb_regressor.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf_regressor = RandomForestRegressor()\n",
    "rf_regressor.fit(X_train_scaled, y_train)\n",
    "y_pred = rf_regressor.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_regressor, '(2)rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already split your data into X_train, X_test, y_train, y_test\n",
    "\n",
    "# Create a Gradient Boosting Regressor object\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gb_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gb_regressor, '(1)gb_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already split your data into X_train, X_test, y_train, y_test\n",
    "\n",
    "# Create a Decision Tree Regressor object\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = dt_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(dt_regressor, '(4)dt_regressor.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle files are numbered based on their accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
